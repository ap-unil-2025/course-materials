<h3>
  Introduction to Data Science and Advanced Programming, HEC Lausanne, Fall
  Semester 2025
</h3>
<p>
  <blockquote>
    <strong>Data Scientist (n.):</strong> <em>Person who is better at statistics than any
    software engineer and better at software engineering than any statistician.</em>
  </blockquote>
</p>
<p>
  This advanced course introduces students to the Python programming language,
  core concepts of statistical learning, and high-performance computing. It is
  designed for Master's students in Economics and Finance to build the
  computational and analytical skills necessary for modern quantitative
  analysis. 
</p>
<p>
  The course consists of three 45-minute lecture sessions and one 45-minute
  hands-on session each week. 
</p>
<p>
  It is offered at HEC Lausanne during the Fall Semester 2025 (Monday, September
  15 - Monday, December 15, 2025).
</p>
<hr>
<h2>Course Objectives</h2>
<p>By the end of this course, you should be able to:</p>
<ul>
  <li>Write clean, efficient, and well-documented Python code.</li>
  <li>Manipulate and analyze data using NumPy and Pandas.</li>
  <li>Create insightful visualizations with Matplotlib and Seaborn.</li>
  <li>Understand the fundamental theory of statistical learning, including the bias–variance trade-off and model assessment.</li>
  <li>Implement and evaluate machine learning models for regression, classification, and clustering using scikit-learn.</li>
  <li>Use tree-based methods and ensemble learning.</li>
  <li>Gain awareness of deep learning concepts and implement a simple neural network.</li>
  <li>Apply basic high-performance computing (HPC) techniques to accelerate Python code.</li>
  <li>Independently manage and execute a data science project from conception to presentation.</li>
</ul>
<hr>
<h2>Meeting time and location</h2>
<ul>
  <li><strong>Time:</strong> Mondays, 12:30–16:00</li>
  <li><strong>Place:</strong> Internef 263</li>
</ul>
<p><strong>TA sessions:</strong> Weekly on Mondays (15:15–16:00) with Anna Smirnova, Francesco
  Brunamonti, and Zhongshan Chen. Individual TA sessions available on Fridays
  upon request.</p>
<hr>
<h2>Class enrollment on the <a href="https://nuvolos.cloud/">Nuvolos Cloud</a></h2>
<ul>
  <li>All lecture materials (slides, codes, and further readings) will be
  distributed via the <a href="https://nuvolos.cloud/">Nuvolos Cloud</a>.</li>
  <li>To enroll in this class, please click on this <a href="https://app.nuvolos.cloud/enroll/class/RshD654gzU4">enrollment
  key</a>, and follow the steps.</li>
</ul>
<hr>
<h2>Video to get started with Nuvolos</h2>
<p>First steps on Nuvolos:</p>
<p>
  <iframe src="https://player.vimeo.com/video/513310246" width="640"
  height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture"
  allowfullscreen></iframe>
</p>
<hr>
<h2>Approximate Schedule</h2>
<p>
  Witness the incredible transformation of a programmer throughout the course,
  from humble beginnings to a master of the craft!
</p>
<p>
  <table style="width:100%; border:0px;">
  <tr>
    <td style="width:33%; vertical-align:top; border:0px;">
      <h3 align="center">Part I: Stone Age Programmer</h3>
      <p align="center">
        <img src="./fig/fig1.png" alt="Stone Age Programmer" style="width:100%;">
      </p>
    </td>
    <td style="width:33%; vertical-align:top; border:0px;">
      <h3 align="center">Part II: Industrial Data Era</h3>
      <p align="center">
        <img src="./fig/fig2.png" alt="Industrial Data Era Programmer" style="width:100%;">
      </p>
    </td>
    <td style="width:34%; vertical-align:top; border:0px;">
      <h3 align="center">Part III: Future Master Programmer</h3>
      <p align="center">
        <img src="./fig/fig3.png" alt="Future Master Programmer" style="width:100%;">
      </p>
    </td>
  </tr>
</table>
</p>
<h3>Part I: Python Foundations (Weeks 1–6)</h3>
<p><strong>Week 1 (Sep 15): Course Overview &amp; Setup</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Introduction to the course</li>
      <li>Structure, grading, and capstone project</li>
      <li>Introduction to Nuvolos cloud computing platform</li>
      <li>Unix/Linux basics</li>
    </ul>
  </li>
</ul>
<p><strong>Week 2 (Sep 22): No Class</strong></p>
<ul>
  <li><em>Swiss Federal Fast (Public Holiday)</em></li>
</ul>
<p><strong>Week 3 (Sep 29): Python Fundamentals I</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Python basics (variables, types)</li>
      <li>Control flow (loops, branching)</li>
      <li>String Manipulation</li>
      <li>Productivity: Git version control, programming style (if time permits)</li>
    </ul>
  </li>
</ul>
<p><strong>Week 4 (Oct 6): Python Fundamentals II</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Function</li>
      <li>Basic Data structures (lists, tuples, dictionaries)</li>
      <li>Recursions</li>
      <li>Jupyter Notebooks (if time permits)</li>
    </ul>
  </li>
</ul>
<p><strong>Week 5 (Oct 13): Special Session: Generative AI</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Hands-on: Large Language Models &amp; Autonomous agents (guest lecture by Anna Smirnova)</li>
    </ul>
  </li>
</ul>
<p><strong>Week 6 (Oct 20): Python Fundamentals III</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Selected Topics on Object Oriented Programming</li>
      <li>Selected Topics on Python Classes and Inheritance</li>
      <li>Basics on Program Efficiency</li>
      <li>A preview on Libraries (take-home materials)</li>
      <li>Productivity: Basics on Testing and Debugging (take-home materials)</li>
      <li>Productivity: Basics on Testing and Debugging -- Notebook (take-home materials)</li>
    </ul>
  </li>
</ul>
<hr>
<h3>Part II: Basics of Data Science (Weeks 7–12)</h3>
<p><strong>Week 7 (Oct 27): Linear Regression</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Supervised Learning - the general idea</li>
      <li>Linear Regression (with multiple variables)</li>
      <li>Gradient Descent</li>
      <li>Polynomial Regression</li>
      <li>Tuning Model Complexity</li>
      <li>Stock Market Prediction (if time permits)</li>
      <li>Introduction to Pandas (quick tour; self-study)</li>
    </ul>
  </li>
  <li>Further Reading: ISL Ch. 3, 5, 6.</li>
  <li>Further Reading: PML Ch. 6.3–6.5 (Bayesian linear regression, uncertainty, model comparison), Ch. 7.1–7.3 (Overfitting, generalization, cross-validation), PML Ch. 6.6 (Regularization as priors: ridge ↔ Gaussian, Lasso ↔ Laplace)</li>
</ul>
<p><strong>Week 8 (Nov 3): Classification</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Supervised Learning: Classification</li>
      <li>k-Nearest-Neighbours</li>
      <li>How to evaluate Classifiers</li>
      <li>Naive Bayes</li>
      <li>Decision Trees</li>
      <li>Combining Models (Boosting, Bagging -- if time permits)</li>
    </ul>
  </li>
  <li>Further Reading: ISL Ch. 4, Ch. 8</li>
  <li>Further Reading: PML Ch. 8.1–8.4 (Logistic regression, generative vs discriminative classifiers), PML Ch. 8.5 (Bayesian logistic regression, optional)</li>
</ul>
<p><strong>Week 9 (Nov 10): Unsupervised Machine Learning</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>k-Means</li>
      <li>Gaussian Mixture Models</li>
      <li>Expectation Maximization</li>
      <li>Principal Component Analysis</li>
      <li>Hierarchical Clustering</li>
      <li>Density-based Clustering</li>
    </ul>
  </li>
  <li>Further Reading: ISL Ch. 10</li>
  <li>Further Reading: PML Ch. 10.1–10.4 (PCA as latent factor model), PML Ch. 11.1–11.3 (Clustering, mixture models, EM algorithm)</li>
</ul>
<p><strong>Week 10 (Nov 17): Deep Learning Primer</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Deep learning basics</li>
      <li>Multi-layer perceptron</li>
      <li>Feed-forward networks</li>
      <li>Network training - SGD</li>
      <li>Error back-propagation</li>
      <li>Some notes on overfitting</li>
      <li>Introduction to Tensorflow, applied to supervised machine learning problems</li>
    </ul>
  </li>
  <li>Further Reading: ISL Ch. 10</li>
  <li>Further Reading: PML Ch. 16 (Neural networks), PML Ch. 17 (Deep learning, optimization &amp; generalization)</li>
</ul>
<p><strong>Week 11 (Nov 24): Best Practices in Data Science</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>A Grand Tour Over the Key Data Science Libraries
        <ul>
          <li>Numpy (if time permits)</li>
          <li>Pandas (if time permits)</li>
          <li>SciPy (if time permits)</li>
          <li>Matplotlib (if time permits)</li>
          <li>SymPy (if time permits)</li>
          <li>scikit-learn (if time permits)</li>
          <li>PyTorch (if time permits)</li>
          <li>Tensorflow (if time permits)</li>
        </ul>
      </li>
      <li>Data Cleaning &amp; Exploratory Data Analysis (EDA)</li>
      <li>Feature Engineering &amp; Preprocessing Pipeline</li>
      <li>Modeling, Evaluation, Thresholding &amp; Interpretation</li>
    </ul>
  </li>
</ul>
<hr>
<h3>Part III: Advanced Programming &amp; Wrap-Up</h3>
<p><strong>Week 12 (Dec 1): Introduction to High-Performance Computing</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Concepts of shared memory parallelization</li>
      <li>Concepts of distributed memory parallelization</li>
      <li>Hybrid parallelization</li>
    </ul>
  </li>
</ul>
<p><strong>Week 13 (Dec 8): High-Performance Computing with Python</strong></p>
<ul>
  <li>Lecture slides, week 13: Concepts of accelerating codes in practice, and shared memory parallelization</li>
  <li>Topics:
    <ul>
      <li>Python for Scientific Computing - the general idea</li>
      <li>Numba (Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code)</li>
      <li>Parallelization/multi-threading</li>
      <li>Multi-threading (if time permits)</li>
      <li>Jax and Flax (self-study)</li>
    </ul>
  </li>
</ul>
<p><strong>Week 14 (Dec 15): Capstone Project Presentations</strong></p>
<ul>
  <li>Topics:
    <ul>
      <li>Students voluntarily present their projects</li>
      <li>Wrap-up and course summary</li>
    </ul>
  </li>
</ul>
<p><img src="./fig/programming_wrapup.png" alt="Young Enthusiastic Professor"></p>
<h2>The Programmer's Journey</h2>
<hr>
<h2>Grading</h2>
<ul>
  <li>Every student has to provide a <strong>capstone project</strong> that illustrates what was learned.</li>
  <li>Each student individually has to propose a data science project and work on it over the course of the semester.</li>
  <li>The due date to submit the project is in the last week of the semester.</li>
  <li>The deliverables are:
    <ul>
      <li>i) a report of about 10 pages lengths.</li>
      <li>ii) a GitHub repository with the related code and data.</li>
      <li>iii) a video recording of a maximum of 10 minutes length that presents the project, the findings, etc.</li>
    </ul>
  </li>
  <li>We will award the grades based on whether the capstone project demonstrates an understanding of the material. <strong>There will be no exams</strong>.</li>
  <li>There will be possibilities to collect "bonus points" via homework assignments.</li>
</ul>
<hr>
<h2>Lecturer</h2>
<ul>
  <li><a href="https://sites.google.com/site/simonscheidegger/">Simon Scheidegger</a>
  (University of Lausanne, Department of Economics)
    <ul>
      <li>Simon Scheidegger: &lt;simon.scheidegger@unil.ch&gt;</li>
    </ul>
  </li>
</ul>
<hr>
<h2>TAs and support</h2>
<ul>
  <li>Anna Smirnova &lt;anna.smirnova@unil.ch&gt; (TA lead)</li>
  <li>Francesco Brunamonti &lt;francesco.brunamonti@unil.ch&gt;</li>
  <li>Zhongshan Chen &lt;zhongshan.chen@unil.ch&gt;</li>
  <li>Nuvolos Support: &lt;support@nuvolos.cloud&gt;</li>
</ul>
<hr>
<h2>Google document for the QA sessions:</h2>
<ul>
  <li><a href="https://docs.google.com/spreadsheets/d/1JnbT8enDgKhR6Rfje0CjtCyMwWXdHXim4iZMpn0QE-A/edit#gid=0">Google Doc</a></li>
</ul>
<hr>
<h2>References</h2>
<ul>
  <li>Guttag, <em>Introduction to Computation and Programming Using Python</em>, MIT Press</li>
  <li>Langtangen, <em>A Primer on Scientific Programming with Python</em>, Springer</li>
  <li>Goodfellow, Bengio, Courville, <a href="http://www.deeplearningbook.org"><em>Deep Learning</em>, MIT Press</a></li>
  <li>Murphy, <a href="http://probml.github.io/book1"><em>Probabilistic Machine Learning: An Introduction</em>, MIT Press</a></li>
  <li>James, Witten, Hastie, Tibshirani, <em>An Introduction to Statistical Learning</em>, 2nd Edition – <a href="https://www.statlearning.com">statlearning.com</a></li>
  <li><a href="https://quantecon.org">QuantEcon</a></li>
</ul>